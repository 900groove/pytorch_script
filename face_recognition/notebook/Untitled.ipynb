{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from pathlib import Path\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:].as_matrix()\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "face_dataset = datasets.ImageFolder(root='../data/train/',\n",
    "                            transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = torch.utils.data.DataLoader(face_dataset,\n",
    "                                             batch_size=50, shuffle=True,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "seed = 1\n",
    "log_interval = 50\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available(): # GPUが利用可能か確認\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(num_classes=2)\n",
    "if device == 'cuda':\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loder, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loder):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx*len(data), len(train_loder.dataset), 100. * batch_idx / len(train_loder), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/9565 (0%)]\tLoss: 0.351854\n",
      "Train Epoch: 1 [5000/9565 (52%)]\tLoss: 0.011116\n",
      "Train Epoch: 2 [0/9565 (0%)]\tLoss: 0.181162\n",
      "Train Epoch: 2 [5000/9565 (52%)]\tLoss: 0.127001\n",
      "Train Epoch: 3 [0/9565 (0%)]\tLoss: 0.120994\n",
      "Train Epoch: 3 [5000/9565 (52%)]\tLoss: 0.095760\n",
      "Train Epoch: 4 [0/9565 (0%)]\tLoss: 0.089401\n",
      "Train Epoch: 4 [5000/9565 (52%)]\tLoss: 0.025563\n",
      "Train Epoch: 5 [0/9565 (0%)]\tLoss: 0.190442\n",
      "Train Epoch: 5 [5000/9565 (52%)]\tLoss: 0.029356\n",
      "Train Epoch: 6 [0/9565 (0%)]\tLoss: 0.057247\n",
      "Train Epoch: 6 [5000/9565 (52%)]\tLoss: 0.012467\n",
      "Train Epoch: 7 [0/9565 (0%)]\tLoss: 0.038670\n",
      "Train Epoch: 7 [5000/9565 (52%)]\tLoss: 0.059204\n",
      "Train Epoch: 8 [0/9565 (0%)]\tLoss: 0.025070\n",
      "Train Epoch: 8 [5000/9565 (52%)]\tLoss: 0.054790\n",
      "Train Epoch: 9 [0/9565 (0%)]\tLoss: 0.013472\n",
      "Train Epoch: 9 [5000/9565 (52%)]\tLoss: 0.038587\n",
      "Train Epoch: 10 [0/9565 (0%)]\tLoss: 0.068778\n",
      "Train Epoch: 10 [5000/9565 (52%)]\tLoss: 0.004765\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "        train(model, device, dataset_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.resnet50(num_classes=2)\n",
    "if device == 'cuda':\n",
    "    model2 = torch.nn.DataParallel(model2, device_ids=range(torch.cuda.device_count()))\n",
    "param = torch.load('../models/model2.pth')\n",
    "model2.load_state_dict(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataset_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = len(face_dataset)\n",
    "class_names = face_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = iter(dataset_loader).next()\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "outputs = model2(inputs)\n",
    "preds = torch.softmax(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7022e-09, 1.0000e+00],\n",
       "        [5.0840e-04, 9.9949e-01],\n",
       "        [1.3385e-05, 9.9999e-01],\n",
       "        [5.9299e-06, 9.9999e-01],\n",
       "        [1.4567e-06, 1.0000e+00],\n",
       "        [1.5545e-05, 9.9998e-01],\n",
       "        [7.8634e-01, 2.1366e-01],\n",
       "        [3.5850e-07, 1.0000e+00],\n",
       "        [2.9949e-05, 9.9997e-01],\n",
       "        [4.7713e-06, 1.0000e+00],\n",
       "        [5.9191e-02, 9.4081e-01],\n",
       "        [3.7469e-03, 9.9625e-01],\n",
       "        [1.9969e-07, 1.0000e+00],\n",
       "        [2.7314e-06, 1.0000e+00],\n",
       "        [5.6472e-11, 1.0000e+00],\n",
       "        [1.0216e-04, 9.9990e-01],\n",
       "        [1.7521e-05, 9.9998e-01],\n",
       "        [8.4031e-08, 1.0000e+00],\n",
       "        [6.6693e-08, 1.0000e+00],\n",
       "        [6.7928e-07, 1.0000e+00],\n",
       "        [6.4485e-07, 1.0000e+00],\n",
       "        [7.0593e-11, 1.0000e+00],\n",
       "        [6.3284e-10, 1.0000e+00],\n",
       "        [2.0819e-05, 9.9998e-01],\n",
       "        [3.3402e-06, 1.0000e+00],\n",
       "        [5.8755e-04, 9.9941e-01],\n",
       "        [1.6127e-04, 9.9984e-01],\n",
       "        [3.1245e-06, 1.0000e+00],\n",
       "        [7.1899e-03, 9.9281e-01],\n",
       "        [4.1157e-08, 1.0000e+00],\n",
       "        [4.2065e-09, 1.0000e+00],\n",
       "        [8.6217e-04, 9.9914e-01],\n",
       "        [3.4167e-04, 9.9966e-01],\n",
       "        [8.4104e-06, 9.9999e-01],\n",
       "        [1.4787e-05, 9.9999e-01],\n",
       "        [1.0561e-04, 9.9989e-01],\n",
       "        [2.3409e-06, 1.0000e+00],\n",
       "        [5.0074e-04, 9.9950e-01],\n",
       "        [7.1678e-09, 1.0000e+00],\n",
       "        [9.4883e-04, 9.9905e-01],\n",
       "        [2.9584e-09, 1.0000e+00],\n",
       "        [4.2000e-09, 1.0000e+00],\n",
       "        [5.5364e-04, 9.9945e-01],\n",
       "        [9.0656e-06, 9.9999e-01],\n",
       "        [7.2274e-06, 9.9999e-01],\n",
       "        [2.4553e-07, 1.0000e+00],\n",
       "        [5.7036e-04, 9.9943e-01],\n",
       "        [3.5795e-11, 1.0000e+00],\n",
       "        [9.3765e-11, 1.0000e+00],\n",
       "        [1.2739e-09, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
